# audio/transcriber.py
"""
Transcri√ß√£o de √°udio usando OpenAI Whisper
"""
import time
import json
import torch
from pathlib import Path
from whisper import load_model
from typing import Optional

class WhisperTranscriber:
    """Classe para gerenciar transcri√ß√£o de √°udio com Whisper"""
    
    def __init__(self, config):
        """
        Inicializa o transcriber
        
        Args:
            config: Inst√¢ncia de Config com configura√ß√µes do sistema
        """
        self.config = config
        self.model = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
    def load_whisper_model(self, model_size: str = "medium"):
        """
        Carrega modelo Whisper
        
        Args:
            model_size: Tamanho do modelo ("tiny", "base", "small", "medium", "large")
        """
        print(f"üîÑ Usando dispositivo para transcri√ß√£o: {self.device}")
        print(f"Carregando modelo Whisper {model_size}...")
        
        self.model = load_model(model_size, device=self.device)
        print("‚úÖ Modelo carregado.")
        
    def transcribe_audio(self) -> bool:
        """
        Transcreve todos os arquivos FLAC no diret√≥rio de √°udio
        
        Returns:
            bool: True se transcri√ß√£o foi bem-sucedida
        """
        # Garante que diret√≥rios existem
        self.config.AUDIO_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
        self.config.TEMP_TRANSCRIPTIONS.mkdir(parents=True, exist_ok=True)
        
        # Carrega modelo se n√£o foi carregado
        if not self.model:
            self.load_whisper_model()
        
        # Encontra arquivos FLAC
        flac_files = sorted(self.config.AUDIO_OUTPUT_DIR.glob("*.flac"))
        if not flac_files:
            print("Nenhum arquivo .flac para transcrever.")
            return False
        
        print(f"üìÅ Encontrados {len(flac_files)} arquivos para transcrever")
        
        # Processa cada arquivo
        for i, audio_file in enumerate(flac_files, 1):
            success = self._transcribe_single_file(audio_file, i, len(flac_files))
            if not success:
                print(f"‚ö†Ô∏è Falha na transcri√ß√£o de {audio_file.name}")
        
        print("‚úÖ Transcri√ß√£o de todos os arquivos conclu√≠da.")
        return True
    
    def _transcribe_single_file(self, audio_file: Path, current: int, total: int) -> bool:
        """
        Transcreve um √∫nico arquivo de √°udio
        
        Args:
            audio_file: Caminho para arquivo de √°udio
            current: N√∫mero atual do arquivo
            total: Total de arquivos
            
        Returns:
            bool: True se transcri√ß√£o foi bem-sucedida
        """
        output_json = self.config.TEMP_TRANSCRIPTIONS / f"{audio_file.stem}.json"
        
        # Pula se j√° foi transcrito
        if output_json.exists():
            print(f"[{current}/{total}] {audio_file.name} j√° transcrito, pulando.")
            return True
        
        print(f"[{current}/{total}] Transcrevendo {audio_file.name} ...")
        start_time = time.time()
        
        try:
            # Executa transcri√ß√£o
            result = self.model.transcribe(
                str(audio_file),
                language="pt",
                fp16=(self.device == "cuda")  # usa FP16 na GPU para acelerar
            )
            
            # Filtra segmentos vazios
            segments = result["segments"]
            segments = [s for s in segments if s.get("text", "").strip()]
            
            # Salva resultado
            with open(output_json, "w", encoding="utf-8") as f:
                json.dump(segments, f, indent=2, ensure_ascii=False)
            
            # Mostra estat√≠sticas
            elapsed = (time.time() - start_time) / 60
            print(f" ‚úÖ Conclu√≠do em {elapsed:.1f} minutos - {len(segments)} segmentos")
            return True
            
        except Exception as e:
            print(f" ‚ùå Erro ao transcrever {audio_file.name}: {e}")
            
            # Fallback para CPU caso falhe na GPU
            if self.device == "cuda":
                print(" ‚ö†Ô∏è Falha na GPU, tentando CPU...")
                self.device = "cpu"
                self.load_whisper_model()  # Recarrega modelo no CPU
                return self._transcribe_single_file(audio_file, current, total)
            
            # Se j√° est√° no CPU, marca como vazio e continua
            with open(output_json, "w", encoding="utf-8") as f:
                json.dump([], f)
            return False
    
    def process_transcription_batch(self, batch_size: int = 4) -> bool:
        """
        Processa transcri√ß√µes em lotes (para otimiza√ß√£o futura)
        
        Args:
            batch_size: N√∫mero de arquivos por lote
            
        Returns:
            bool: True se processamento foi bem-sucedido
        """
        # Por enquanto, chama transcri√ß√£o individual
        # Futura implementa√ß√£o pode incluir processamento paralelo
        return self.transcribe_audio()
    
    def get_transcription_stats(self) -> dict:
        """
        Retorna estat√≠sticas das transcri√ß√µes
        
        Returns:
            dict: Estat√≠sticas das transcri√ß√µes
        """
        transcription_files = list(self.config.TEMP_TRANSCRIPTIONS.glob("*.json"))
        total_segments = 0
        total_duration = 0
        
        for file in transcription_files:
            try:
                with open(file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    total_segments += len(data)
                    if data:
                        total_duration += data[-1].get('end', 0)
            except Exception:
                continue
        
        return {
            'total_files': len(transcription_files),
            'total_segments': total_segments,
            'estimated_duration_minutes': total_duration / 60,
            'device_used': self.device
        }

def create_transcriber(config):
    """Fun√ß√£o utilit√°ria para criar inst√¢ncia do transcriber"""
    return WhisperTranscriber(config)